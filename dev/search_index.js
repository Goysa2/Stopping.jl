var documenterSearchIndex = {"docs":
[{"location":"api/#Types-1","page":"API","title":"Types","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"Stopping.GenericStopping\nStopping.NLPStopping\nStopping.LS_Stopping\nStopping.StoppingMeta","category":"page"},{"location":"api/#Stopping.GenericStopping","page":"API","title":"Stopping.GenericStopping","text":"Type : GenericStopping  Methods : start!, stop!\n\nA generic stopping criterion to solve instances (pb) with respect to some  optimality conditions (optimality_check)  Besides optimality conditions, we consider classical emergency exit:\n\nunbounded problem\nstalled problem\ntired problem (measured by the number of evaluations of functions and time)\n\nInput :     - pb         : An problem     - state      : The information relative to the problem     - (opt) meta : Metadata relative to stopping criterion. Can be provided by \t\t\t\t   the user or created with the Stopping constructor with kwargs \t\t\t\t   If a specific StoppingMeta is given as well as kwargs are \t\t\t\t   provided, the kwargs have priority.     - (opt) main_stp : Stopping of the main loop in case we consider a Stopping                        of a subproblem.                        If not a subproblem, then of type Nothing.\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.NLPStopping","page":"API","title":"Stopping.NLPStopping","text":"Stopping structure for non-linear programming problems. Inputs:\n\npb : An AbstractNLPModel\noptimality_check : a stopping criterion through an admissibility function\nmeta : StoppingMeta\nmax_cntrs :: Dict contains the max number of evaluations\ncurrent_state : the current state of the problem (i.e an NLPAtX)\noptimality_check : takes two inputs (AbstractNLPModel, NLPAtX)\n\nand returns a Float64 to be compared at 0.  (Idée: ajouter une nouvelle input mainpb dans le optimalitycheck?)\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.LS_Stopping","page":"API","title":"Stopping.LS_Stopping","text":"LSStopping is designed to handle the stopping criterion of line search problems. Let f:R→Rⁿ, then h(t) = f(x+td) where x and d are vectors and t is a scalar. h is such that h:R→R. h is a LineModel defined in SolverTools.jl (https://github.com/JuliaSmoothOptimizers/SolverTools.jl) It is possible to define those stopping criterion in a NLPStopping except NLPStopping uses vectors operations. LSStopping and it's admissible functions (Armijo and Wolfe are provided with Stopping.jl) uses scalar operations. In order to work properly within the Stopping framework, admissible functions must return a value that will be compare to 0. For instance, the armijo condition is h(t)-h(0)-τ₀th'(0) ⩽ 0 therefore armijo(h, hatt) returns the maximum between h(t)-h(0)-τ₀th'(0) and 0. The inputs of an admissible function are :     - h \t :: A LineModel     - hatt :: A line search state, defined in State.jl\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.StoppingMeta","page":"API","title":"Stopping.StoppingMeta","text":"StoppingMeta Common stopping criterion for \"all\" optimization algorithms such as:     - absolute and relative tolerance     - threshold for unboundedness     - time limit to let the algorithm run     - maximum number of function (and derivatives) evaluations\n\nIt's a mutable struct therefore we can modified elements of a StoppingMeta. \t- The nbofstop is incremented everytime stop! or updateandstop! is called \t- The optimality0 is modified once at the beginning of the algorithm (start!)     - The starttime is modified once at the beginning of the algorithm (start!)     if not precised before. \t- The different status optimalsub_pb, unbounded, tired, stalled, optimal and \t  infeasible are modified according to the data of the algorithm.\n\n\n\n\n\n","category":"type"},{"location":"api/#General-Functions-1","page":"API","title":"General Functions","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"Stopping.update_and_start!\nStopping.update_and_stop!\nStopping.fill_in!\nStopping.start!\nStopping.stop!\nStopping.reinit!\nStopping.status","category":"page"},{"location":"api/#Stopping.update_and_start!","page":"API","title":"Stopping.update_and_start!","text":"updateandstart!: Update the values in the State and initializes the Stopping Returns the optimity status of the problem.\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.update_and_stop!","page":"API","title":"Stopping.update_and_stop!","text":"updateandstop!: Update the values in the State and returns the optimity status of the problem.\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.fill_in!","page":"API","title":"Stopping.fill_in!","text":"fill_in!: A function that fill in the unspecified values of the AbstractState.\n\n\n\n\n\nfill_in! : A function that fill in the required values in the State\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.start!","page":"API","title":"Stopping.start!","text":"start!:  Input: Stopping.  Output: optimal or not.  Purpose is to know if there is a need to even perform an optimization algorithm or if we are  at an optimal solution from the beginning.\n\nNote: start! initialize the start_time (if not done before) and meta.optimality0.\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.stop!","page":"API","title":"Stopping.stop!","text":"stop!: Inputs: Interface Stopping. Output: optimal or not. Serves the same purpose as start! When in an algorithm, tells us if we stop the algorithm (because we have reached optimality or we loop infinitely, etc).\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.reinit!","page":"API","title":"Stopping.reinit!","text":"reinit!:  Input: Stopping.  Output: Stopping modified.  Reinitialize the meta data filled in by the start!\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.status","page":"API","title":"Stopping.status","text":"status: Takes an AbstractStopping as input. Returns the status of the algorithm:     - Optimal : if we reached an optimal solution     - Unbounded : if the problem doesn't have a lower bound     - Stalled : if we did too  many iterations of the algorithm     - Tired : if the algorithm takes too long     - ResourcesExhausted: if we used too many ressources,                           i.e. too many functions evaluations     - ResourcesOfMainProblemExhausted: in the case of a substopping, ResourcesExhausted or Tired     for the main stopping.     - Infeasible : default return value, if nothing is done the problem is                    considered infeasible     - DomainError : there is a NaN somewhere\n\n\n\n\n\n","category":"function"},{"location":"api/#Non-linear-admissibility-functions-1","page":"API","title":"Non linear admissibility functions","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"Stopping.unconstrained\nStopping.KKT","category":"page"},{"location":"api/#Stopping.unconstrained","page":"API","title":"Stopping.unconstrained","text":"unconstrained: return the infinite norm of the gradient of the objective function\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.KKT","page":"API","title":"Stopping.KKT","text":"To be documented\n\n\n\n\n\n","category":"function"},{"location":"api/#Line-search-admissibility-functions-1","page":"API","title":"Line search admissibility functions","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"Stopping.armijo\nStopping.wolfe\nStopping.armijo_wolfe","category":"page"},{"location":"api/#Stopping.armijo","page":"API","title":"Stopping.armijo","text":"Check if a step size is admissible according to the Armijo criterion. Inputs: Any, #LineModel and LSAtT. Outputs: admissibility in the armijo sense Armijo criterion: f(x + θd) - f(x) < τ₀ ∇f(x+θd)d\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.wolfe","page":"API","title":"Stopping.wolfe","text":"Check if a step size is admissible according to the Wolfe criterion. Inputs: Any, #LineModel and LSAtT. Outputs: admissibility in the Strong Wolfe sense. Strong Wolfe criterion: |∇f(x+θd)| < τ₁||∇f(x)||.\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.armijo_wolfe","page":"API","title":"Stopping.armijo_wolfe","text":"Check if a step size is admissible according to both the Armijo and Wolfe criterion. Inputs: Any, #LineModel and LSAtT. Outputs: admissibility in the Strong Wolfe sense. Strong Wolfe criterion: |∇f(x+θd)| < τ₁||∇f(x)||.\n\n\n\n\n\n","category":"function"},{"location":"#Stopping.jl-1","page":"Home","title":"Stopping.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Documentation for Stopping.jl","category":"page"},{"location":"#Purpose-1","page":"Home","title":"Purpose","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Tools to ease the uniformization of stopping criteria in iterative solvers.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"When a solver is called on an optimization model, four outcome may happen:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"the approximate solution is obtained, the problem is considered solved\nthe problem is declared unsolvable (unboundedness, infeasibility ...)\nthe maximum available ressources is not sufficient to compute the solution\nsome algorithm dependent failure happens","category":"page"},{"location":"#","page":"Home","title":"Home","text":"This tool eases the first 3 items above. It defines a type","category":"page"},{"location":"#","page":"Home","title":"Home","text":"mutable struct GenericStopping <: AbstractStopping\n    problem       :: Any          # an arbitrary instance of a problem\n    meta          :: StoppingMeta # contains the used parameters\n    current_state :: State        # the current state","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The StoppingMeta provides default tolerances, maximum ressources, ...  as well as (boolean) information on the result.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"We provide some specialization of the GenericStopping for instance :","category":"page"},{"location":"#","page":"Home","title":"Home","text":"NLPStopping: for non-linear programming;\nLS_Stopping: for 1d optimization;\nmore to come...","category":"page"},{"location":"#","page":"Home","title":"Home","text":"In these examples, the function optimality_residual computes the residual of the optimality conditions is an additional attribute of the type.","category":"page"},{"location":"#Functions-1","page":"Home","title":"Functions","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The tool provides two functions:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"start!(stp :: AbstractStopping) initializes the time and the tolerance at the starting point and check wether the initial guess is optimal.\nstop!(stp :: AbstractStopping) checks optimality of the current guess as well as failure of the system (unboundedness for instance) and maximum ressources (number of evaluations of functions, elapsed time ...)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The stopping uses the informations furnished by the State to evaluate its functions. Communication between the two can be done through the following functions:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"update_and_start!(stp :: AbstractStopping; kwargs...) updates the states with informations furnished as kwargs and then call start!.\nupdate_and_stop!(stp :: AbstractStopping; kwargs...) updates the states with informations furnished as kwargs and then call stop!.\nfill_in!(stp :: AbstractStopping, x :: Iterate) a function that fill in all the State with all the informations required to correctly evaluate the stopping functions. This can reveal useful, for instance, if the user do not trust the informations furnished by the algorithm in the State.","category":"page"},{"location":"#How-to-install-1","page":"Home","title":"How to install","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The stopping package can be installed and tested through the Julia package manager:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"(v0.7) pkg> add https://github.com/Goysa2/Stopping.jl\n(v0.7) pkg> test Stopping","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Note that the package State.jl is required and can be installed also through the package manager:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"(v0.7) pkg> add https://github.com/Goysa2/State.jl","category":"page"},{"location":"#Example-1","page":"Home","title":"Example","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"As an example, a naïve version of the Newton method is provided. First we import the packages:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"using NLPModels, State, Stopping","category":"page"},{"location":"#","page":"Home","title":"Home","text":"We create an uncontrained quadratic optimization problem using NLPModels:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"A = rand(5, 5); Q = A' * A;\n\nf(x) = 0.5 * x' * Q * x\nnlp = ADNLPModel(f,  ones(5))","category":"page"},{"location":"#","page":"Home","title":"Home","text":"We use our NLPStopping structure by creating our State and Stopping:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"nlp_at_x = NLPAtX(ones(5))\nstop_nlp = NLPStopping(nlp, (x,y) -> Stopping.unconstrained(x,y), nlp_at_x)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Now a basic version of Newton to illustrate how to use State and Stopping.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"function newton(stp :: NLPStopping)\n    state = stp.current_state; xt = state.x;\n    update!(state, x = xt, gx = grad(stp.pb, xt), Hx = hess(stp.pb, xt))\n    OK = start!(stp)\n\n    while !OK\n        d = -inv(state.Hx) * state.gx\n\n        xt = xt + d\n\n        update!(state, x = xt, gx = grad(stp.pb, xt), Hx = hess(stp.pb, xt))\n\n        OK = stop!(stp)\n    end\n\n    return stp\nend\n\nstop_nlp = newton(stop_nlp)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"We can look at the meta to know what happened","category":"page"},{"location":"#","page":"Home","title":"Home","text":"@show stop_nlp.meta.tired #ans: false\n@show stop_nlp.meta.unbounded #ans: false\n@show stop_nlp.meta.optimal #ans: true","category":"page"},{"location":"#","page":"Home","title":"Home","text":"We reached optimality!","category":"page"},{"location":"#Long-Term-Goals-1","page":"Home","title":"Long-Term Goals","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Future work will adress more sophisticated problems such as mixed integer optimization problems, optimization with uncertainty. The list of suggester optimality functions will be enriched with state of the art conditions.","category":"page"},{"location":"tutorial/#Tutorials-and-examples-1","page":"Examples and tutorials","title":"Tutorials and examples","text":"","category":"section"},{"location":"tutorial/#","page":"Examples and tutorials","title":"Examples and tutorials","text":"Coming soon!","category":"page"}]
}
